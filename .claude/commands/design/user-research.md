# Conduct User Research

I need you to conduct user research to understand user needs, pain points, and behaviors.

## Context

**Research Goal**: $ARGUMENTS

(Examples: "Understand why users churn after onboarding", "Validate new feature idea", "Improve checkout conversion", "Identify power user workflows", "Persona development for marketing")

## Your Task

Route this to the **ux-researcher** agent who will:

1. **Define Research Questions**:
   - Primary question: [Main thing you need to learn]
   - Secondary questions: [Supporting insights]
   - Success criteria: [What answers would be actionable?]
   - Hypotheses to test: [What do you believe and need to validate?]

   **Example**:
   > Primary: "Why do 60% of users drop off during onboarding?"
   > Secondary: "What steps confuse users?", "What motivates users to continue?"
   > Hypothesis: "Users drop off because signup requires too much info upfront"

2. **Choose Research Method**:
   **Qualitative Methods** (understand WHY):
   - **User Interviews** (1-on-1, 30-60 min):
     - Best for: Deep insights, exploratory research, validating assumptions
     - Sample size: 5-10 users (diminishing returns after 5)
     - Recruitment: Existing users, target audience
   - **Usability Testing** (observe users completing tasks):
     - Best for: Identifying friction points, validating designs
     - Sample size: 5 users (uncovers 85% of issues)
     - Tasks: 3-5 realistic scenarios
   - **Contextual Inquiry** (observe users in their environment):
     - Best for: Understanding workflows, real-world usage
     - Sample size: 5-8 users
   - **Diary Studies** (users log experiences over time):
     - Best for: Long-term behavior, habit formation
     - Duration: 1-4 weeks
   - **Focus Groups** (group discussion, 6-10 people):
     - Best for: Brainstorming, diverse perspectives
     - Use sparingly (groupthink risk)

   **Quantitative Methods** (understand WHAT and HOW MUCH):
   - **Surveys** (structured questions, large sample):
     - Best for: Validating insights at scale, prioritization
     - Sample size: 100+ respondents (statistical significance)
     - Tools: Typeform, Google Forms, SurveyMonkey
   - **Analytics Analysis** (product usage data):
     - Best for: Understanding behavior patterns, funnel drop-offs
     - Tools: Mixpanel, Amplitude, Google Analytics
   - **A/B Testing** (compare variants):
     - Best for: Validating design changes, optimization
     - Sample size: Varies (use calculator)
   - **Tree Testing** (information architecture):
     - Best for: Navigation structure, findability
     - Sample size: 50+ users

3. **Recruit Participants**:
   **Screening Criteria**:
   - Demographics: [Age, location, occupation]
   - Behavioral: [Product usage, frequency, role]
   - Psychographic: [Goals, motivations, pain points]

   **Recruitment Channels**:
   - Existing users: In-app message, email
   - Target audience: UserTesting, Respondent.io, User Interviews
   - Social media: Reddit, Facebook groups, Twitter
   - Incentives: $50-100 gift cards, product credits, early access

   **Sample Screener Question**:
   > "How often do you use [product category]?"
   > a) Daily (✅ recruit)
   > b) Weekly (✅ recruit)
   > c) Monthly (maybe)
   > d) Rarely (reject)

4. **Create Research Protocol**:
   **Interview Script** (semi-structured):
   - Introduction (5 min):
     - Thank participant
     - Explain purpose, confidentiality
     - Ask permission to record
     - Icebreaker question
   - Background questions (10 min):
     - Current solutions
     - Pain points
     - Workflows
   - Main questions (30 min):
     - Open-ended ("Tell me about a time when...")
     - Follow-up probes ("Can you elaborate?", "Why is that important?")
     - Avoid leading questions ("Don't you think...?")
   - Wrap-up (5 min):
     - Final thoughts
     - Thank you, incentive delivery

   **Usability Testing Protocol**:
   - Task scenarios (realistic, not prescriptive):
     - ❌ "Click the 'Sign Up' button"
     - ✅ "You want to create an account. How would you do that?"
   - Think-aloud protocol (ask users to verbalize thoughts)
   - Observer notes (record observations, quotes, pain points)
   - Success criteria (task completion rate, time on task, errors)

5. **Conduct Research**:
   **Interview Best Practices**:
   - Build rapport (warm, curious, non-judgmental)
   - Ask open-ended questions ("Tell me about...", "Walk me through...")
   - Avoid yes/no questions
   - Embrace silence (give users time to think)
   - Probe for specifics ("Can you give an example?")
   - Stay neutral (don't defend product decisions)

   **Usability Testing Best Practices**:
   - Observe, don't intervene (resist urge to help)
   - Note emotional reactions (frustration, delight, confusion)
   - Ask "What are you thinking?" if user gets stuck
   - Test on realistic devices (mobile, desktop, slow internet)

   **Recording & Note-Taking**:
   - Record sessions (Zoom, Loom, UserTesting)
   - Take verbatim notes (user quotes are gold)
   - Tag insights (pain points, delighters, feature requests)

6. **Analyze Findings**:
   **Thematic Analysis**:
   - Transcribe sessions (Otter.ai, Rev.com)
   - Code observations (tag recurring themes)
   - Affinity mapping (group similar insights):
     - Pain points
     - Delighters
     - Feature requests
     - Behavioral patterns
   - Prioritize by frequency and severity

   **Usability Metrics**:
   - Task success rate (% of users completing task)
   - Time on task (average duration)
   - Error rate (mistakes made)
   - Satisfaction (post-task rating)
   - System Usability Scale (SUS score, target > 68)

   **Survey Analysis**:
   - Quantitative: Averages, distributions, correlations
   - Open-ended: Code responses, sentiment analysis
   - Segmentation: Compare by user type (new vs power users)

7. **Synthesize Insights**:
   **User Personas** (if applicable):
   - Name and photo (humanize)
   - Demographics and role
   - Goals and motivations
   - Pain points and frustrations
   - Behavioral patterns ("A day in the life")
   - Quote: "I wish I could..."

   **Journey Maps**:
   - Stages (awareness → consideration → purchase → usage → advocacy)
   - User actions at each stage
   - Touchpoints (where users interact)
   - Pain points and emotions
   - Opportunities for improvement

   **Jobs-to-be-Done Framework**:
   - "When [situation], I want to [motivation], so I can [outcome]"
   - Example: "When I'm onboarding a new client, I want to quickly set up their account, so I can start delivering value immediately"

8. **Create Research Report**:
   **Executive Summary** (1 page):
   - Research goals
   - Key findings (top 3-5 insights)
   - Recommendations (prioritized)
   - Next steps

   **Main Report**:
   - Methodology (who, when, how)
   - Participant profiles
   - Detailed findings (organized by theme):
     - Insight + supporting evidence (quotes, data)
     - Severity (critical, high, medium, low)
   - Recommendations with rationale
   - Appendix (raw data, screener, script)

   **Presentation Format** (for stakeholders):
   - 10-15 slides max
   - Heavy on quotes and video clips
   - Visualize data (charts, journey maps)
   - End with actionable next steps

9. **Turn Insights into Action**:
   **Prioritization**:
   - Impact vs Effort matrix
   - Quick wins (high impact, low effort)
   - Strategic bets (high impact, high effort)
   - Deprioritize (low impact)

   **Feature Briefs**:
   - Problem statement (from research)
   - User need (job-to-be-done)
   - Proposed solution
   - Success metrics

   **Design Principles** (derived from research):
   - "Always show progress" (users felt lost)
   - "One click to value" (reduce friction)
   - "Guide, don't overwhelm" (progressive disclosure)

10. **Share and Socialize**:
    - Present findings to team (live readout)
    - Create highlight reel (video clips of key insights)
    - Add insights to knowledge base (searchable repository)
    - Regular "Research Insights" newsletter
    - Display user quotes in office/Slack (build empathy)

## Deliverables

- Research plan (goals, method, participants, timeline)
- Discussion guide or usability testing protocol
- Recorded sessions and transcripts
- Synthesized findings report (insights, quotes, data)
- User personas or journey maps (if applicable)
- Actionable recommendations (prioritized)
- Presentation for stakeholders

## Research Timeline

**Week 1: Planning**
- Define research questions
- Choose method
- Create protocol
- Recruit participants

**Week 2: Data Collection**
- Conduct interviews/tests (5-10 sessions)
- Take detailed notes
- Record sessions

**Week 3: Analysis**
- Transcribe sessions
- Code themes
- Synthesize insights
- Create report

**Week 4: Socialization**
- Present findings
- Create personas/journey maps
- Prioritize recommendations
- Kickoff design/implementation

## Success Criteria

- Actionable insights: Clear recommendations with evidence
- Stakeholder buy-in: Team aligned on priorities
- User empathy: Team references insights in decisions
- Impact: Features shipped based on research improve metrics

## Research Tools

**Recruitment**: UserTesting, Respondent.io, User Interviews
**Moderation**: Zoom, Google Meet, Lookback
**Surveys**: Typeform, SurveyMonkey, Google Forms
**Analytics**: Mixpanel, Amplitude, FullStory
**Note-taking**: Dovetail, Airtable, Notion
**Transcription**: Otter.ai, Rev.com
**Prototyping**: Figma, Framer, Maze

**Route to**: System Coordinator → Design Coordinator → ux-researcher
